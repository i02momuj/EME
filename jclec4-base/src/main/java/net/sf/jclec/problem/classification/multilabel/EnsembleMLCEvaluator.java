package net.sf.jclec.problem.classification.multilabel;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Comparator;
import java.util.Hashtable;
import java.util.List;
import java.util.logging.Level;
import java.util.logging.Logger;

import mulan.data.MultiLabelInstances;
import mulan.classifier.MultiLabelLearner;
import mulan.classifier.MultiLabelOutput;
import mulan.classifier.transformation.LabelPowerset;
import mulan.evaluation.Evaluator;
import mulan.evaluation.Evaluation;
import mulan.evaluation.measure.AveragePrecision;
import mulan.evaluation.measure.Coverage;
import mulan.evaluation.measure.ErrorSetSize;
import mulan.evaluation.measure.ExampleBasedAccuracy;
import mulan.evaluation.measure.ExampleBasedFMeasure;
import mulan.evaluation.measure.ExampleBasedPrecision;
import mulan.evaluation.measure.ExampleBasedRecall;
import mulan.evaluation.measure.ExampleBasedSpecificity;
import mulan.evaluation.measure.GeometricMeanAverageInterpolatedPrecision;
import mulan.evaluation.measure.GeometricMeanAveragePrecision;
import mulan.evaluation.measure.HammingLoss;
import mulan.evaluation.measure.HierarchicalLoss;
import mulan.evaluation.measure.IsError;
import mulan.evaluation.measure.LogLoss;
import mulan.evaluation.measure.MacroAUC;
import mulan.evaluation.measure.MacroPrecision;
import mulan.evaluation.measure.MacroRecall;
import mulan.evaluation.measure.MacroSpecificity;
import mulan.evaluation.measure.MeanAverageInterpolatedPrecision;
import mulan.evaluation.measure.MeanAveragePrecision;
import mulan.evaluation.measure.Measure;
import mulan.evaluation.measure.MacroFMeasure;
import mulan.evaluation.measure.MicroAUC;
import mulan.evaluation.measure.MicroFMeasure;
import mulan.evaluation.measure.MicroPrecision;
import mulan.evaluation.measure.MicroRecall;
import mulan.evaluation.measure.MicroSpecificity;
import mulan.evaluation.measure.OneError;
import mulan.evaluation.measure.RankingLoss;
import mulan.evaluation.measure.SubsetAccuracy;
import weka.classifiers.trees.J48;
import net.sf.jclec.IFitness;
import net.sf.jclec.IIndividual;
import net.sf.jclec.base.AbstractParallelEvaluator;
import net.sf.jclec.binarray.BinArrayIndividual;
import net.sf.jclec.fitness.SimpleValueFitness;
import net.sf.jclec.fitness.ValueFitnessComparator;
import net.sf.jclec.util.random.IRandGenFactory;


public class EnsembleMLCEvaluator extends AbstractParallelEvaluator
{
	/////////////////////////////////////////////////////////////////
	// --------------------------------------- Serialization constant
	/////////////////////////////////////////////////////////////////
	
	/** Generated by Eclipse */
	
	protected static final long serialVersionUID = -2635335580011827514L;
	
	/////////////////////////////////////////////////////////////////
	// --------------------------------------------------- Properties
	/////////////////////////////////////////////////////////////////
	
	/* Dataset to build the ensemble */
	protected MultiLabelInstances datasetTrain;
	
	/* Dataset to evaluate the individuals */
	protected MultiLabelInstances datasetValidation;
	
	/* Number of active labels in each base classifier */
	protected int numberLabelsClassifier;
	
	/* Number of base classifiers of the ensemble */
	protected int numberClassifiers;
	
	/* Threshold for voting process prediction*/
	protected double predictionThreshold;
	
	/* Indicates if the number of active labels is variable for each base classifier */
	protected boolean variable;
	
	/* Indicates if the fitness is a value to maximize */
	protected boolean maximize = true;
	
	/* Base learner for the classifiers of the ensemble */
	public MultiLabelLearner baseLearner;
	
	/* Fitness values comparator */
	protected Comparator<IFitness> COMPARATOR = new ValueFitnessComparator(!maximize);
	
	/* Table that stores all base classifiers built */
	public Hashtable<String, MultiLabelLearner> tableClassifiers;
	
	/* Table that stores the fitness of all evaluated individuals */
	public Hashtable<String, Double> tableFitness;
	
	/* Matrix with phi correlations between labels */
	double [][] phiMatrix;
	
	/* Indicates if the individual diversity is contemplated in fitness */
	private boolean fitnessWithIndividualDiversity = false;
	
	/* Random numbers generator */
	protected IRandGenFactory randGenFactory;
	
	/////////////////////////////////////////////////////////////////
	// ------------------------------------------------- Constructors
	/////////////////////////////////////////////////////////////////
	
	/**
	* Empty constructor.
	*/
	public EnsembleMLCEvaluator()
	{
		super();
	}
	
	/////////////////////////////////////////////////////////////////
	// ----------------------------------------------- Public methods
	/////////////////////////////////////////////////////////////////
	
	public int getNumberClassifiers()
	{
		return numberClassifiers;
	}
	
	public MultiLabelInstances getDatasetTrain()
	{
		return datasetTrain;
	}
	
	public MultiLabelInstances getDatasetValidation()
	{
		return datasetValidation;
	}
	
	public void setDatasetTrain(MultiLabelInstances datasetTrain) {
		this.datasetTrain = datasetTrain;
	}
	
	public void setDatasetValidation(MultiLabelInstances datasetValidation) {
		this.datasetValidation = datasetValidation;
	}

	public void setNumberClassifiers(int numberClassifiers) {
		this.numberClassifiers = numberClassifiers;
	}

	public void setNumberLabelsClassifier(int numberLabelsClassifier) {
		this.numberLabelsClassifier = numberLabelsClassifier;
	}
	
	public void setPredictionThreshold(double predictionThreshold) {
		this.predictionThreshold = predictionThreshold;
	}
	
	public void setVariable(boolean variable) {
		this.variable = variable;
	}
	
	public void setBaseLearner(MultiLabelLearner baseLearner)
	{
		this.baseLearner = baseLearner;
	}
	
	public Comparator<IFitness> getComparator() {
		return COMPARATOR;
	}
	
	public boolean getFitnessWithIndividualDiversity()
	{
		return fitnessWithIndividualDiversity;
	}
	
	public void setFitnessWithIndividualDiversity(boolean b)
	{
		fitnessWithIndividualDiversity = b;
	}
	
	public void setTable(Hashtable<String, MultiLabelLearner> tableClassifiers) {
		this.tableClassifiers = tableClassifiers;
	}
	
	public void setTableMeasures(Hashtable<String, Double> tableFitness) {
		this.tableFitness = tableFitness;
	}
	
	public void setPhiMatrix(double [][] matrix)
	{
		phiMatrix = matrix;
	}
	
	 public void setRandGenFactory(IRandGenFactory randGenFactory)
	 {
		 this.randGenFactory = randGenFactory;
	 }
	
	/////////////////////////////////////////////////////////////////
	// ------------------------ Overwriting AbstractEvaluator methods
	/////////////////////////////////////////////////////////////////
	
	@Override
	protected void evaluate(IIndividual ind) 
	{
		// Individual genotype
		byte[] genotype = ((BinArrayIndividual) ind).getGenotype();
		
		// Create classifier
		EnsembleClassifier classifier = new EnsembleClassifier(numberLabelsClassifier, numberClassifiers, predictionThreshold, variable, new LabelPowerset(new J48()), genotype, tableClassifiers, randGenFactory.createRandGen());
		
		Evaluator eval = new Evaluator();          
		
        try {
        	    // Build classifier using train data
        	    classifier.build(datasetTrain);

        	    
        	    List<Measure> measures = new ArrayList<Measure>();  	       
  	       	  	measures.add(new HammingLoss());
  	       	  	Evaluation results;
  	       	  	
  	       	  	// Obtain ensembleMatrix
  	       	  	byte [][] ensembleMatrix = classifier.getEnsembleMatrix();
  	       	  	String s = classifier.getOrderedStringFromEnsembleMatrix();
  	       	  	
  	       	  	double fitness = -1;
  	       	  	//Try to get the individual fitness from the table
  	       	  	if(tableFitness.containsKey(s))
  	       	  	{
  	       	  		fitness = tableFitness.get(s).doubleValue();
  	       	  	}
  	       	  	else
  	       	  	{
  	       	  		//Evaluate the ensemble with the validation set
  	       	  		results = eval.evaluate(classifier, datasetValidation, measures);
  	       	  		
  	       	  		if(fitnessWithIndividualDiversity)
  	       	  		{
  	       	  			int max = 0;
	  				
  	       	  			/*
  	       	  			 * Calculate the individual diversity:
  	       	  			 * 		- Calculate the maximum number of repetitions of a label
  	       	  			 * 		- Divide max by possible number of appearances
  	       	  			 * 		- The diversity is 1 -  (try to have a balanced appearance of labels)
  	       	  			 */
		  				for(int i=0; i<getDatasetTrain().getNumLabels(); i++)
		  				{
		  					int sum = 0;
		  					
		  					for(int j=0; j<getNumberClassifiers(); j++)
		  					{
		  						sum = sum + genotype[i+j*getDatasetTrain().getNumLabels()];
		  					}
		  					
		  					if (sum > max)
		  						max = sum;
		  				}		  				
		  				//The diversity is the opposite of the max number of label repeat
		  				double div = 1 - (double)max/getNumberClassifiers();
	  	       	  		
		  				//maximize (1 - HLoss)
		  				double measure = results.getMeasures().get(0).getValue(); //Only one metric is available
		  				measure = 1 - measure;
		  				
		  				if(maximize)
		  				{
		  					fitness = results.getMeasures().get(0).getValue()*0.6 + div*0.4;
		  				}
		  				else
		  				{
		  					//The diversity is to maximize, so if fitness is to minimize, we have to minimize (1-diversity)
		  					fitness = results.getMeasures().get(0).getValue()*0.6 + (1-div)*0.4;
		  				}
  	       	  		}
  	       	  		else
  	       	  		{
  	       	  			double measure = results.getMeasures().get(0).getValue();
  	       	  			//measure is Hloss -> 1-Hloss is to maximize
  	       	  			measure = 1 - measure;
  	       	  			fitness = measure;	
  	       	  			
  	       	  			/*
  	       	  			 * Introduces Phi correlation in fitness
  	       	  			
  	       	  			double phiTotal = 0;
  	       	  			
  	       	  			//Calculate sumPhi for all base classifiers
  	       	  			for(int c=0; c<getNumberClassifiers(); c++)
  	       	  			{
  	       	  				double sumPhi = 0;
  	       	  				//calculate sum of phi label correlations for a base classifier
  	       	  				for(int i=0; i<getDatasetTrain().getNumLabels()-1; i++)
  	       	  				{
  	       	  					for(int j=i+1; j<getDatasetTrain().getNumLabels(); j++)
  	       	  					{
  	       	  						if((ensembleMatrix[c][i] == 1) && (ensembleMatrix[c][j] == 1))
  	       	  							sumPhi += Math.abs(phiMatrix[i][j]);
  	       	  					}
  	       	  				}
  	       	  				
  	       	  				phiTotal += sumPhi;
  	       	  			}
  	       	  			
  	       	  			fitness = measure + phiTotal;
  	       	  			
  	       	  			*/
  	       	  		}
	  				
  	       	  		tableFitness.put(s, fitness);
  	       	  	}
  	       	  	
  	       	  	ind.setFitness(new SimpleValueFitness(fitness));

			} catch (IllegalArgumentException e) {
				e.printStackTrace();
			} catch (Exception e) {
				e.printStackTrace();
			}	
	}

}