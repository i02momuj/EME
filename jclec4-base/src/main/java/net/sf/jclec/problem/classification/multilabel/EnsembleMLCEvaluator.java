package net.sf.jclec.problem.classification.multilabel;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Comparator;
import java.util.Hashtable;
import java.util.List;
import java.util.logging.Level;
import java.util.logging.Logger;

import mulan.data.MultiLabelInstances;
import mulan.classifier.MultiLabelLearner;
import mulan.classifier.MultiLabelOutput;
import mulan.classifier.transformation.LabelPowerset;
import mulan.evaluation.Evaluator;
import mulan.evaluation.Evaluation;
import mulan.evaluation.measure.AveragePrecision;
import mulan.evaluation.measure.Coverage;
import mulan.evaluation.measure.ErrorSetSize;
import mulan.evaluation.measure.ExampleBasedAccuracy;
import mulan.evaluation.measure.ExampleBasedFMeasure;
import mulan.evaluation.measure.ExampleBasedPrecision;
import mulan.evaluation.measure.ExampleBasedRecall;
import mulan.evaluation.measure.ExampleBasedSpecificity;
import mulan.evaluation.measure.GeometricMeanAverageInterpolatedPrecision;
import mulan.evaluation.measure.GeometricMeanAveragePrecision;
import mulan.evaluation.measure.HammingLoss;
import mulan.evaluation.measure.HierarchicalLoss;
import mulan.evaluation.measure.IsError;
import mulan.evaluation.measure.LogLoss;
import mulan.evaluation.measure.MacroAUC;
import mulan.evaluation.measure.MacroPrecision;
import mulan.evaluation.measure.MacroRecall;
import mulan.evaluation.measure.MacroSpecificity;
import mulan.evaluation.measure.MeanAverageInterpolatedPrecision;
import mulan.evaluation.measure.MeanAveragePrecision;
import mulan.evaluation.measure.Measure;
import mulan.evaluation.measure.MacroFMeasure;
import mulan.evaluation.measure.MicroAUC;
import mulan.evaluation.measure.MicroFMeasure;
import mulan.evaluation.measure.MicroPrecision;
import mulan.evaluation.measure.MicroRecall;
import mulan.evaluation.measure.MicroSpecificity;
import mulan.evaluation.measure.OneError;
import mulan.evaluation.measure.RankingLoss;
import mulan.evaluation.measure.SubsetAccuracy;
import weka.classifiers.trees.J48;
import net.sf.jclec.IFitness;
import net.sf.jclec.IIndividual;
import net.sf.jclec.base.AbstractParallelEvaluator;
import net.sf.jclec.binarray.BinArrayIndividual;
import net.sf.jclec.fitness.SimpleValueFitness;
import net.sf.jclec.fitness.ValueFitnessComparator;
import net.sf.jclec.util.random.IRandGenFactory;


public class EnsembleMLCEvaluator extends AbstractParallelEvaluator
{
	/////////////////////////////////////////////////////////////////
	// --------------------------------------- Serialization constant
	/////////////////////////////////////////////////////////////////
	
	/** Generated by Eclipse */
	
	protected static final long serialVersionUID = -2635335580011827514L;
	
	/////////////////////////////////////////////////////////////////
	// --------------------------------------------------- Properties
	/////////////////////////////////////////////////////////////////
	
	protected MultiLabelInstances datasetTrain;
	
	protected MultiLabelInstances datasetValidation;
	
	protected int numberLabelsClassifier;
	
	protected int numberClassifiers;
	
	protected double predictionThreshold;
	
	protected boolean variable;
	
	protected boolean maximize = true;
	
	public MultiLabelLearner baseLearner;
	
	protected Comparator<IFitness> COMPARATOR = new ValueFitnessComparator(!maximize);
	
	public Hashtable<String, MultiLabelLearner> tableClassifiers;
	
	public Hashtable<String, Double> tableFitness;
	
	double [][] phiMatrix;
	
	private boolean fitnessWithIndividualDiversity = false;
	
	protected IRandGenFactory randGenFactory;
	
	/////////////////////////////////////////////////////////////////
	// ------------------------------------------------- Constructors
	/////////////////////////////////////////////////////////////////
	
	/**
	* Empty constructor.
	*/
	public EnsembleMLCEvaluator()
	{
		super();
	}
	
	/////////////////////////////////////////////////////////////////
	// ----------------------------------------------- Public methods
	/////////////////////////////////////////////////////////////////
	
	public int getNumberClassifiers()
	{
		return numberClassifiers;
	}
	
	public MultiLabelInstances getDatasetTrain()
	{
		return datasetTrain;
	}
	
	public MultiLabelInstances getDatasetValidation()
	{
		return datasetValidation;
	}
	
	public void setDatasetTrain(MultiLabelInstances datasetTrain) {
		this.datasetTrain = datasetTrain;
	}
	
	public void setDatasetValidation(MultiLabelInstances datasetValidation) {
		this.datasetValidation = datasetValidation;
	}

	public void setNumberClassifiers(int numberClassifiers) {
		this.numberClassifiers = numberClassifiers;
	}

	public void setNumberLabelsClassifier(int numberLabelsClassifier) {
		this.numberLabelsClassifier = numberLabelsClassifier;
	}
	
	public void setPredictionThreshold(double predictionThreshold) {
		this.predictionThreshold = predictionThreshold;
	}
	
	public void setVariable(boolean variable) {
		this.variable = variable;
	}
	
	public void setBaseLearner(MultiLabelLearner baseLearner)
	{
		this.baseLearner = baseLearner;
	}
	
	public Comparator<IFitness> getComparator() {
		return COMPARATOR;
	}
	
	public boolean getFitnessWithIndividualDiversity()
	{
		return fitnessWithIndividualDiversity;
	}
	
	public void setFitnessWithIndividualDiversity(boolean b)
	{
		fitnessWithIndividualDiversity = b;
	}
	
	public void setTable(Hashtable<String, MultiLabelLearner> tableClassifiers) {
		this.tableClassifiers = tableClassifiers;
	}
	
	public void setTableMeasures(Hashtable<String, Double> tableFitness) {
		this.tableFitness = tableFitness;
	}
	
	public void setPhiMatrix(double [][] matrix)
	{
		phiMatrix = matrix;
	}
	
	 public void setRandGenFactory(IRandGenFactory randGenFactory)
	 {
		 this.randGenFactory = randGenFactory;
	 }
	
	/////////////////////////////////////////////////////////////////
	// ------------------------ Overwriting AbstractEvaluator methods
	/////////////////////////////////////////////////////////////////
	
	@Override
	protected void evaluate(IIndividual ind) 
	{
		// Individual genotype
		byte[] genotype = ((BinArrayIndividual) ind).getGenotype();
		
		// Create classifier
		EnsembleClassifier classifier = new EnsembleClassifier(numberLabelsClassifier, numberClassifiers, predictionThreshold, variable, new LabelPowerset(new J48()), genotype, tableClassifiers, randGenFactory.createRandGen());
		
		Evaluator eval = new Evaluator();          
		
        try {
        	    // Build classifier using train data
        	    classifier.build(datasetTrain);

        	    List<Measure> measures = new ArrayList<Measure>();  	       
  	       	  	measures = prepareMeasures(classifier, datasetTrain);
  	       	  	Evaluation results;
  	       	  	
  	       	  	// Obtain ensembleMatrix  	       	  	
  	       	  	byte [][] ensembleMatrix = classifier.getEnsembleMatrix();
  	       	  	
  	       	  	String s = getStringFromEnsembleMatrix(ensembleMatrix, classifier.getNumClassifiers(), classifier.getNumLabels());
  	       	  	
  	       	  	double fitness = -1;
  	       	  	//Try to get the individual fitness from the table
  	       	  	if(tableFitness.containsKey(s))
  	       	  	{
  	       	  		fitness = tableFitness.get(s).doubleValue();
  	       	  	}
  	       	  	else
  	       	  	{
  	       	  		results = eval.evaluate(classifier, datasetValidation, measures);
  	       	  		String mName = new String();
  	       	  		mName = "Hamming Loss";
  	       	  		
  	       	  		if(fitnessWithIndividualDiversity)
  	       	  		{
  	       	  			int max = 0;
	  				
		  				for(int i=0; i<getDatasetTrain().getNumLabels(); i++)
		  				{
		  					int sum = 0;
		  					
		  					for(int j=0; j<getNumberClassifiers(); j++)
		  					{
		  						sum = sum + genotype[i+j*getDatasetTrain().getNumLabels()];
		  					}
		  					
		  					//System.out.println("sum: " + sum);
		  					if (sum > max)
		  						max = sum;
		  				}
		  				
		  				//The diversity is the opposite of the max number of label repeat
		  				double div = 1 - (double)max/getNumberClassifiers();
	  	       	  		
		  				if(maximize)
		  					fitness = getMeasureValue(mName, results)*0.6 + div*0.4;
		  				else
		  					fitness = getMeasureValue(mName, results)*0.6 + (1-div)*0.4;
  	       	  		}
  	       	  		else
  	       	  		{
  	       	  			//Introduces phi correlation in fitness
  	       	  			double measure = getMeasureValue(mName, results);
  	       	  			//measure is Hloss -> 1-Hloss is to maximize
  	       	  			measure = 1 - measure;
  	       	  			fitness = measure;	
  	       	  			
  	       	  			/*
  	       	  			 * Introduces Phi correlation in fitness
  	       	  			
  	       	  			double phiTotal = 0;
  	       	  			
  	       	  			//Calculate sumPhi for all base classifiers
  	       	  			for(int c=0; c<getNumberClassifiers(); c++)
  	       	  			{
  	       	  				double sumPhi = 0;
  	       	  				//calculate sum of phi label correlations for a base classifier
  	       	  				for(int i=0; i<getDataset().getNumLabels()-1; i++)
  	       	  				{
  	       	  					for(int j=i+1; j<getDataset().getNumLabels(); j++)
  	       	  					{
  	       	  						if((ensembleMatrix[c][i] == 1) && (ensembleMatrix[c][j] == 1))
  	       	  							sumPhi += Math.abs(phiMatrix[i][j]);
  	       	  					}
  	       	  				}
  	       	  				
  	       	  				phiTotal += sumPhi;
  	       	  			}
  	       	  			
  	       	  			fitness = measure + phiTotal;
  	       	  			
  	       	  			*/
  	       	  			
  	       	  		}	  	       	  	

	  				
  	       	  		tableFitness.put(s, fitness);
  	       	  	}
  	       	  	
  	       	  	ind.setFitness(new SimpleValueFitness(fitness));

			} catch (IllegalArgumentException e) {
				e.printStackTrace();
			} catch (Exception e) {
				e.printStackTrace();
			}	
	}
	
	protected List<Measure> prepareMeasures(MultiLabelLearner learner,
            MultiLabelInstances mlTestData) {
        List<Measure> measures = new ArrayList<Measure>();

        MultiLabelOutput prediction;
        try {
            prediction = learner.makePrediction(mlTestData.getDataSet().instance(0));
            int numOfLabels = mlTestData.getNumLabels();
            
            // add bipartition-based measures if applicable
            if (prediction.hasBipartition()) {
                // add example-based measures
                measures.add(new HammingLoss());
                measures.add(new SubsetAccuracy());
                measures.add(new ExampleBasedPrecision());
                measures.add(new ExampleBasedRecall());
                measures.add(new ExampleBasedFMeasure());
                measures.add(new ExampleBasedAccuracy());
                measures.add(new ExampleBasedSpecificity());
                // add label-based measures
                measures.add(new MicroPrecision(numOfLabels));
                measures.add(new MicroRecall(numOfLabels));
                measures.add(new MicroFMeasure(numOfLabels));
                measures.add(new MicroSpecificity(numOfLabels));
                measures.add(new MacroPrecision(numOfLabels));
                measures.add(new MacroRecall(numOfLabels));
                measures.add(new MacroFMeasure(numOfLabels));
                measures.add(new MacroSpecificity(numOfLabels));
            }
            // add ranking-based measures if applicable
            if (prediction.hasRanking()) {
                // add ranking based measures
                measures.add(new AveragePrecision());
                measures.add(new Coverage());
                measures.add(new OneError());
                measures.add(new IsError());
                measures.add(new ErrorSetSize());
                measures.add(new RankingLoss());
            }
            // add confidence measures if applicable
            if (prediction.hasConfidences()) {
                measures.add(new MeanAveragePrecision(numOfLabels));
                measures.add(new GeometricMeanAveragePrecision(numOfLabels));
                measures.add(new MeanAverageInterpolatedPrecision(numOfLabels, 10));
                measures.add(new GeometricMeanAverageInterpolatedPrecision(numOfLabels, 10));
                measures.add(new MicroAUC(numOfLabels));
                measures.add(new MacroAUC(numOfLabels));
                measures.add(new LogLoss());
            }
            // add hierarchical measures if applicable
            if (mlTestData.getLabelsMetaData().isHierarchy()) {
                measures.add(new HierarchicalLoss(mlTestData));
            }
        } catch (Exception ex) {
            Logger.getLogger(Evaluator.class.getName()).log(Level.SEVERE, null, ex);
        }

        return measures;
    }
	
	
	protected double getMeasureValue (String measureName, Evaluation results)
	{
		double mvalue = -1;
		
		for(int i=0; i<results.getMeasures().size(); i++)
		{
			if(results.getMeasures().get(i).getName().equals(measureName))
			{
				mvalue = results.getMeasures().get(i).getValue();
				break;
			}
		}
		
		if(mvalue == -1)
		{
			System.out.println("Incorrect name of the measure. Correct are: ");
			for(int i=0; i<results.getMeasures().size(); i++)
			{
				System.out.println("   " + results.getMeasures().get(i).getName());
			}
			System.exit(-1);
		}
		
		return mvalue;
	}
	
	protected String getStringFromEnsembleMatrix(byte [][] ensembleMatrix, int numClassifiers, int numLabels)
	{
		
		String [] matrix = new String[numClassifiers];
     	  	
		// EnsembleMatrix to Strings array
     	for(int i=0; i<numClassifiers; i++)
     	{
     		String s = new String();
     			
     		for(int j=0; j<numLabels; j++)
     		{
     			s = s+ensembleMatrix[i][j];
     		}
     	 		
     		matrix[i] = s;
     	}

     	// Ordered list of rows of the EnsembleMatrix
     	Arrays.sort(matrix);
     		
     	String s2 = new String();
     	 	
	    for(int i=0; i<numClassifiers; i++)
	    {
	    	s2 = s2 + matrix[i];
	    }
		
		return s2;
	}


}